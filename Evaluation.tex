\chapter{Implementation} \label{Implementation}

As mentioned in the preceding chapters, the development of the simulation environment was as much a goal of this thesis as any; we seek to lay the groundwork for further investigation in this field with a credible system that reproduces faithfully the conditions found in a dense, urban environment with many devices capable of accessing the network. Ideally, the work presented here will be refined and will continue to be used on investigations in this area.

For the creation of such a testing environment, five elements were recognized as of utmost importance to the validity of the tests and the author sought to implement them accordingly. In the following, they will be presented with detail, justifying the sources of the models and the parameter choices made.

The aforementioned elements are:

\begin{itemize}
	\item Generation and distribution of UEs %\ref{PPP}
	\item Path loss (attenuation) %\ref{PL}
	\item Shadow fading %\ref{SF}
	\item Random access procedure and interference %\ref{RAP}
  \item Clustering algorithms
\end{itemize}

The actual simulations, as well as the measures used to quantify the relative performance of each algorithm are presented in chapter \ref{Results}.

\section{Generation and distribution of UEs} \label{PPP}
Often called a ``completely'' random process, a Poisson process is a process where every event is stochastically independent of all other points in it, see \cite{Keeler2016}. This generation process is common in investigations about the performance of networks, as eloquently expressed by \cite{Keeler} In our case, the Poisson-distributed random variable are the number of points in the bounded region we are investigating. The distribution is described by the following probability mass function:

\begin{equation} \label{eq:Poisson}
f_X(x\,\text{points in region}) = \frac{{e^{ - \lambda } \lambda ^x }}{{x!}}
\end{equation}

By providing the $\lambda$ above, often called mean density (\cite{Keeler2016}), we can adjust the expected amount of points generated in a given area. In order to evaluate the robustness of different algorithms, the tests were made with a variety of $\lambda$ values. The generated amount of points are then distributed in the given area with a uniform distribution, where both the $x$ and $y$ value are distributed along the appropriate axis. In both cases, the \textit{Python} package \textit{NumPy} was utilized for the realization of the random distributions.

\begin{figure}[!h]
\centering
\includegraphics[scale = 0.6]{figures/PPP}
\caption{Example of a PPP with $\lambda = 200$}
\end{figure}

Thus we have generated the number and position of all our UEs according to a Poisson point process (PPP).

\section{Path loss (attenuation)} \label{PL}
Whenever transmission between devices is being investigated, loss due to attenuation as the signal propagates through space is an unavoidable topic. Distance degrades electromagnetic waves in terms of power in any real system and any simulation that does not reflect this phenomenon is simply not valid. 

In search of the best documented and most forward-looking models available, we settled on the use of METIS (Mobile and wireless communications Enablers for the Twenty-twenty Information Society), a EU Project that seeks to promote the definition of 5G mobile technologies. Its channel model, presented in its deliverables (\cite{Raschkowski}) was especially insightful. 

For the purposes of this thesis, the Stochastic Model, a ``geometry-based stochastic channel model'', was chosen for the way it lined up with our own goals, especially when it came to level of detail and complexity. Their figures are based on previous efforts by 3GPP studies to model these same phenomena. Due to the highly dense, urban system we are investigating, propagation scenario number one, ``Urban Micro'' was selected. Due to the constraints of this thesis, we narrowed our focus on Outside-to-Outside (020) connections, although the integration of Outside-to-Inside (O2I) could be a feature of future research.

When calculating the attenuation for a given path between two devices, there emerge two distinct cases, depending on whether there are any significant obstacles between the two of them: Line-of-sight (LOS) and Non-line-of-sight (NLOS).



\subsection{Manhattan grid} \label{mh_grid}
In order to determine whether a given link is a LOS or NLOS link, we need information about the obstacles present in the path between the two. In our case, we don't consider objects like cars and people explicitly, but rather account for all such minor objects and reflections they might create with a stochastic model (see \ref{SF}). Buildings, on the other hand, represent such massive, nigh-impenetrable objects that we must contemplate them concretely.

The preferred method mentioned in the METIS deliverables is the use of a ``Manhattan-like'' grid, meaning a city-layout comprised of rectangular blocks criss-crossed by wide streets. To determine both the size and the overall layout of our Manhattan Grid, we again turn to the extensive work done by METIS. The measurements with which their relevant models were tested were run in Madrid, with a grid of around 500 meters of both length and width. We homogenized the scenario by having exclusively square blocks, but maintained both the street width and the general dimensions. We also fixed the position of the eNodeB exactly at the middle of the grid for those clustering algorithms that needed its position.


\begin{table}[htbp]
\begin{center}
 \begin{tabular}{||p{3cm}|p{3cm}||} 
 \hline
 \textbf{Parameter} & \textbf{Value}\\
 \hline\hline
 Grid Dimensions & 500 m $\times$ 500 m \\ 
 \hline
 Block Width & 110 m \\
 \hline
 Block Length & 110 m \\
 \hline
 Street Width & 20 m \\
 \hline
 eNB position & (250\,\text{m},\,250\,\text{m})\\
 \hline
\end{tabular}
\end{center}
\caption{Manhattan grid parameters}
\end{table}

The introduction of an explicit grid raises the issue of the positioning of our UEs again. Having scattered them in a Poisson point process (see \ref{PPP}), some inevitably now find themselves inside a building and not on the street, as is necessary for our O2O simulations. We overcome this obstacle by simply finding the shortest route from the position inside a block to the street: as the UE position is random, so too is the route taken. Thus we avoid completely discarding the randomness of their positioning. The results can be seen in figure \ref{fig:mh_grid_own} and compared to the actual city grid used for METIS measurements (figure \ref{fig:Madrid}).

\begin{figure}
\centering
\begin{subfigure}{.35\textwidth}
  \centering
  \includegraphics[width=1.2\linewidth]{figures/Madrid}
  \caption{Madrid grid \cite{Raschkowski}}
  \label{fig:Madrid}
\end{subfigure}%
\begin{subfigure}{.65\textwidth}
  \centering
  \includegraphics[width=1.058\linewidth]{figures/mh_grid}
  \caption{Own implementation, including moved UEs}
  \label{fig:mh_grid_own}
\end{subfigure}
\caption{Comparison between two Manhattan Grids}
\label{fig:mh_grid}
\end{figure}


With a Manhattan-like layout at the ready, questions about whether a link has LOS or not become much easier to answer.

\subsection{Line-of-sight} \label{LOS}
The overall model for pathloss used by \cite{Raschkowski} is derived specifically from the one presented in \cite{ReportITU-RM.2135-12009} by the ITU (International Telecommunication Union) and covers a wide frequency range (0.8 to 60 GHz). Distances between 10 and 500 meters are thus defined by two distinct equations, depending on whether the distance between the two points is greater than a certain ``breakpoint distance''. The distance $d^\prime_{BP}$ in question is defined by
\begin{equation} \label{eq:dbp}
d^\prime_{BP} = 0.87\, \exp\bigg( -\frac {log_{10} \big( \frac {f_c} {1\,\text{GHz}} \big)} {0.65} \,\bigg)\,\frac{4\,h^\prime_{BS}h^\prime_{UE}}{\lambda_{WL}}\,,
\end{equation}
with $h^\prime_{BS}$ as the effective height of the Base Station and $h^\prime_{UE}$ the effective height of the UE, with ``effective" denoting adjusting for environment height $h_e$. The $\lambda_{WL}$ is the wavelength of the signal, which is calculated from the center frequency $f_c$ and the speed of light $c$. It must be mentioned that for our transmissions, the height of both the origin and destination device will be identical more often than not, due to cluster connections being D2D links.

An additional ``pathloss offset'' $PL_1$ is defined in order to bring the model in agreement with the control measurements performed by METIS and is designed to account for elements like multipath fading.

\begin{equation} \label{eq:PL_1}
PL_{1|dB} = -1.38\,\log_{10}\,\bigg( \frac {f_c}{1\,\text{Ghz}} \bigg) + 3.34
\end{equation}


The actual pathloss equations are given as a function of distance $d$ by

\begin{equation} \label{eq:PL_LOS_1}
  PL_{LOS}(d)_{|dB} = 10\,n_1\,\log_{10}\bigg( \frac{d}{1\,\text{m}} \bigg) + 28.0 + 20 \log_{10} \bigg( \frac{f_c}{1\,\text{GHz}} \bigg) + PL_{1|dB}
\end{equation}
for $10\,\text{m}\,<\,d\, \le \,d^\prime_{BP}$ and
\begin{equation} \label{eq:PL_LOS_2}
  PL_{LOS}(d)_{|dB} = 10\,n_2\,\log_{10}\bigg( \frac{d}{d^\prime_{BP}} \bigg) + PL_{LOS}(d^\prime_{BP})_{|dB}
\end{equation}
for $d^\prime_{BP}\,<\,d\, \le \,500\,\text{m}$ (compare with \cite{Raschkowski}). The parameters $n_1 = 2.2$ and $n_2 = 4.0$ are the power decay constant on both sides of the break point distance.

\subsection{Non-line-of-sight} \label{NLOS}
Most of the connections available to a given UE will be NLOS links. These happen whenever the UE tries to communicate with a device that is not on its same street and thus the signal has to travel a more convoluted way in order to be received. METIS defers explicitly to the final channel models, created by WINNER+ (Wireless World Initiative New Radio+) in \cite{Heino2010}. WINNER+ is a private consortium looking to further develop the IMT-A (International Mobile Telecommunications-Advanced) standards. 

The conceptual NLOS model in itself comes from an even earlier work, \cite{Meinila2009}, which details the relevant parameters for NLOS communication in an urban setting. In these cases, the corners resulting from intersecting streets act as relay nodes for the signal. \cite{Meinila2009} designates two distances needed to calculate the pathloss in this route, see figure \ref{fig:d1_d2}, where $d_1$ is distance from relay node to BS and $d_2$ to the UE. As was the case for the difference in heights between UE and BS, seeing as the links we are investigating are D2D, there is no real clear theoretical distinction between $d_1$ and $d_2$. However, we keep the distinction intact (with the same emitter/receiver relation) owing to the fact that ``[t]hough the pathloss between BS and UE must be the same regardless of the direction of signal transmission due to reciprocity, the pathloss \textit{models} do not necessarily hold the reciprocity'' (\cite{Raschkowski}).

\begin{figure}
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{figures/node_relay}
  \caption{Node Relay example \cite{Raschkowski}}
  \label{fig:node_relay}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{figures/d1_d2}
  \caption{Distances $d_1$ and $d_2$ \cite{Meinila2009}}
  \label{fig:d1_d2}
\end{subfigure}
\caption{Calculation of NLOS path}
\label{fig:nlos_path}
\end{figure}

Thus, the formula for pathloss in the studied case is presented in \cite{Raschkowski} after a small simplification and again featuring the ``pathloss offset'' (equation \ref{eq:PL_1}) mentioned in \ref{LOS}:

%\begin{equation} \label{eq:NLOS}
\begin{equation} \label{eq:NLOS}
\begin{split}
  PL_{NLOS}(d_1,d_2)_{|\text{dB}} = & \,PL_{LOS}(d_1)_{|\text{dB}} + 17.9 - 12.5\,n_j \\
  & + 10\,n_j\,\log_{10} \bigg( \frac {d_2} {1 \text{m}} \bigg) + 3 \log_{10} \bigg( \frac { f_c } { 1 \text{GHz} } \bigg) + PL_{1|\text{dB}},
\end{split}
\end{equation}
where $n_j$ is a power decay constant calculated as

\begin{equation} \label{eq:n_j}
n_j = \max (2.8 - 0.0024\,d_1,\,1.84).
\end{equation}

In a rectangular Manhattan grid such as ours, a only two intersections are needed as relays in order to connect any two given points on the grid. An algorithm was thus created to calculate the shortest possible distance between the two devices using a maximum of two intersections. We take the shortest possible route because the signal spreads omni-directionally. An example of a calculated route between two points can be seen in figure \ref{fig:two_points}.

\begin{figure}[H]
\centering
\includegraphics[width=.7\linewidth]{figures/two_points}
\caption{Visualization of NLOS path with intersection acting as relay node}
\label{fig:two_points}
\end{figure}

\section{Shadow fading} \label{SF}
As mentioned in \ref{mh_grid}, Shadow Fading - meaning the effects on the signal caused by smaller obstacles - as well as the reflections they create are modelled through a stochastic model. This type of fluctuation, called ``Shadow Fading'' or ``long-term fading'' is often realized through a Gaussian distribution in the logarithmic scale (also called a log-normal distribution), as asserted in \cite{Forkel2004} and shown below in its probability density function. In our case, we followed METIS specifications and set $\mu_{L_s} = 0$ and $\sigma_{L_s} = 7 \text{dB}$.

\begin{equation} \label{eq:SF}
p(L_s) = \frac{1}{{\sigma_{L_s} \sqrt {2\pi } }}\,\exp\bigg(-\frac{(L_s - \mu_{L_s})^2}{2\,\sigma_{L_s}^2}\bigg)
\end{equation}

While any given point is distributed randomly along the normal distribution, completely random and uncorrelated shadow fading variables make little sense when one considers that the effects of any given set of obstacles won't change much in the space of a couple of meters. In order to account for the necessary correlation that these shadow fading variables experience, a normalized autocorrelation function is introduced, both in \cite{Forkel2004} and \cite{Raschkowski}, with a decorrelation value suggested by METIS $d_{corr} = 8 m$.

\begin{equation} \label{eq:corr}
R(\Delta x) = \exp\bigg(-\frac{|\Delta x|}{d_{corr}}\,\ln(2)\bigg)
\end{equation}

After generating the shadow fading variables with equation \ref{eq:SF} and the autocorrelation coefficients with equation \ref{eq:corr}, both matrices are convoluted to generate the correlated values. Convolution does not alter the underlying distribution, but it does elicit a correction of the mean and standard deviation (compare with \cite{Forkel2004}) in order to return it to the values of the original Gaussian distribution. Our realization is shown below, both before and after the aforementioned correction for spatial correlation.

%\centering
\begin{figure}
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1.1\linewidth]{figures/noise_before}
  \caption{Uncorrelated Shadow Fading values}
  \label{fig:sf_no_correlation}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1.1\linewidth]{figures/noise_after}
  \caption{Correlated Shadow Fading values}
  \label{fig:sf_correlated}
\end{subfigure}
\caption{Shadow Fading values before and after correlation adjustment}
\label{fig:SF}
\end{figure}


These shadow fading fading values are added to the pathloss values in order to fully account for all the obstacles in the way of the signal between two devices. The complete attenuation value then determines the received signal strength at the target device.

A summary of the relevant parameters utilized for the calculation of the pathloss can be seen in table \ref{tbl:PL}, part of chapter \ref{Results}.


\section{Random access procedure and interference} \label{RAP}
When reducing the load that the eNB experiences as a result of an increase in the amount of devices connecting to it by means of clustering, a large amount of the load is simply transferred to the cluster heads. These have then to take up the functions of the eNB in terms of implementing a random access procedure through which to service the UEs connecting to it. As mentioned in section \ref{B:D2D}, we contemplate an explicit separation of resources for normal BS to UE communication and D2D communication, putting further constraints on the ability of the cluster head to detect and separate signals using the same resource blocks. In order to best model these kinds of phenomena, the author utilized simulations developed by his supervisor, M.Sc. Mikhail Vilgelm, that were kindly put at his disposition for this work.

Firstly, a Poisson process is used in modeling the arrival of packages proceeding from connected UEs to the appropriate cluster head. This Poisson arrival process is analogous to that shown in equation \ref{eq:Poisson} and yields the amount of packages arrived at a certain point in time instead of points in an area. The arrival rate of requests to a given cluster, $\lambda_A$ was set by recommendation of the author's supervisor to a level where the derivative of the throughput with respect to the arrival rate is positive, at $\lambda_A = 1.5$. It is important to note here that the arrival rate is fixed for each cluster head. This means that no matter the amount of UEs connecting to said cluster head, the mean expected amount of requests in a given time frame also remains at a fixed level.

The requests are generated at the given rate and broadcast with a set transmission power $P_{Tx}$. Although there are many proposals for power control schemes in D2D communications, such as \cite{Erturk2013}, \cite{Wei2012} or \cite{Lee}, due to there being so many varied schemes and them adding such complexity to the simulation, it was decided that power control would not be part of the scope of this work. As in \cite{Klugel2014a}, we decide to use $P_{Tx} = 23\,\text{dBm}$ for our simulation, which is incidentally the power level used for coverage issue identification in \cite{3rdGenerationPartnershipProject;2012} and the maximum transmit power for public safety defined in \cite{3rdGenerationPartnershipProject;}, both by the 3GPP.

The power is then affected by the appropriate attenuation at the spot of the receiving device (see section \ref{PL}) and the resulting power is the received power $P_{Rx|dBm} = P_{Tx|dBm} - PL_{|dB}$. In order to assess whether a given signal has reached the cluster head with enough power to be detected, we look at the SINR (Signal-to-Interference-and-Noise-Ratio) of the transmission. For the calculation of the noise we use a thermal noise density $N_0 = -174\,\frac{\text{dBm}}{\text{Hz}}$, UE receiver noise figure $NF_{UE} = 9\,\text{dB}$ and system bandwidth $W = 10\,\text{MHz}$, as defined in \cite{3rdGenerationPartnershipProject;2012}, see equation \ref{eq:noise}.

\begin{equation}\label{eq:noise}
P_{N|dBm} = N_0 \cdot W + NF_{|dB}
\end{equation} 

The incoming requests are checked for additional interference coming from other requests using the same preamble, both within and without the cluster. The received power $I$ of those interfering signals at the cluster head are added and that total added to the noise power $P_N$ to finally calculate the SINR, see equation \ref{eq:SINR}. As mentioned earlier, the available preambles for transmission of a D2D link are drawn from the overall pool of preambles available in LTE-A. As mentioned in \cite{Cox2012}, 64 preambles are available to the cell, only 6 of which are available for D2D communication. This is to allow normal cellular UEs to experience an acceptable QoS (Quality of Service), while still allowing other devices access to the network.

\begin{equation}\label{eq:SINR}
SINR = \frac {P_{Rx}} {I + P_N}
\end{equation}

As to the minimum SINR needed to connect to the cluster head, a threshold of $SINR_{thr} = 10\,\text{dB}$ was chosen within the range presented in \cite{3Gpp2009} for the minimum ratio necessary to transmit with ``an acceptably low BER (Bit Error Rate) in the output data.'' Those requests under the threshold will be filtered out before they are dealt with by the cluster head. Please note that although they are not counted towards successful requests, they will count towards interference values of other requests that may or may not clear the threshold.

Finally, requests clearing the threshold will be handled by the cluster head, who will then check for intra-cluster preamble collisions and give feedback, negative or positive, to the UEs. For simplicity's sake, feedback is assumed to arrive safely back at the UE; positive feedback elicits no action from the original transmitter. Upon reception of negative feedback, on the other hand, the UE ``backs off'' for an amount of time before attempting the connection once again at a later point in time. If the device is told to back off 20 times, it assumes the connection has failed completely and will not try again until another packet is generated at that UE. The time for each slot was set at $10\,\text{ms}$, while the overall simulation duration was put at $5\,\text{s}$.

Readers can find a summary of all used parameters for this stage on table \ref{tbl:RA}, in chapter \ref{Results}.

The last piece of the puzzle is, of course, the actual mapping of UEs to cluster heads. These are fed into the random access and interference simulation by the clustering algorithms.

\section{Clustering Algorithms} \label{ClusteringAlgs}
Clustering algorithms determine which UEs will be connected to which cluster heads, as well as which UEs will turn into cluster heads in the first place. Because of the nature of our research (regarding D2D communication), we eschewed any schemes that required dedicated gateways into the networks. In the definition of the scope of this work, we also decided to leave out any algorithms with multi-hop possibilities, simply due to the sheer complexity that would have represented. Algorithms presented here thus feature only one aggregation stage at the cluster head, which then forwards the data to the eNB.

Most of the work done in clustering algorithms for wireless networks comes from the area of Wireless Sensor Networks (WSN), where large amounts of sensor nodes form a network communicating with a central unit of control. These types of structures lend themselves especially to grouping and aggregation, considering especially that there is often a lot of redundancy in the collected data. Energy efficiency and resilience of networks is often of paramount importance, in an attempt to minimize maintenance overhead. There have been several studies about clustering algorithms in this area, such as \cite{Jiang2009} or \cite{Afsar2014}. Unfortunately, the fundamentally different nature between static sensors and LTE-A capable devices severely limits the applicability of most schemes to our scenario.

Additionally to a WSN algorithm we included schemes normally used in statistical data analysis, specifically a couple of hierarchical clustering schemes. These feature a progressive merging of clusters depending on a variety of criteria; distance is often used when determining the level of kinship two points or clusters possess. Hierachical clustering is preferred over other types of schemes due to us working under the assumption that there is few information present in the system a priori. This assumption makes the necesary estimation of the final number of clusters (cf. \cite{Everitt2011}) exceedingly complicated; implementing advanced heuristics or other such techniques to overcome this was of no interest to us.

When possible, we have tried instead to use measures relevant to our research area, such as Signal-to-Noise Ratio (SNR) and Signal-to-Interference-and-Noise Ratio (SINR) to quantify connectivity. 

\subsection{LEACH} \label{LEACH}
One of the most influential clustering algorithms in WSNs is LEACH (Low-Energy Adaptive Clustering Hierarchy), presented in \cite{Heinzelman2000}. Despite its relative age, it promised ``localized coordination to enable scalability and robustness for dynamic networks'' and was designed to lower the amount of information transmitted to the base station. As can be seen in \cite{Afsar2014}, it has spawned many other algorithms based on its simple premises. 

LEACH works by randomly assigning its nodes as cluster heads according to a certain formula intended to yield a desired percentage $P_{LEACH}$ of CHs. Each node generates a uniformly distributed number between 0 and 1 and compares it to a threshold value $T(n)$. If the generated number is over that threshold it is designated to function as a cluster head.

Once cluster heads have been assigned for the whole of the network, an advertisement is broadcast, announcing to the other UEs which cluster heads are available. UEs then take the received signal strength as a proxy for distance and elect the nearest to their location. We simulate this behavior by creating a link to the received signal with the highest SNR. Signal must exceed an SNR of 0 to even be considered for a potential link, in order to ensure the advertisement is distinguishable from the noise. 

LEACH is designed to work with several rounds of CH assignment and data transfer in order to rotate the burden of CH selection, assuming a fixed set of nodes for a relatively long period of time. Seeing how our scenario is short-lived and features ideally mobile nodes, as well as a highly mutable network layout, we eschew the round structure. Consequently, the resulting  formula for the generation of the threshold value $T(n)$ can be seen in equation \ref{eq:LEACH}

\begin{equation}\label{eq:LEACH}
T(n) = \frac {P_{LEACH}}{1-P_{LEACH}\,(\text{mod}\,\frac {1}{P_{LEACH}})}
\end{equation}

Having observed just how many other clustering schemes it inspired, we decided to give LEACH particular importance in our testing, running simulations for it with a wider range of point densities $\lambda$, as well as more fine-grained data points.


\subsection{Complete-Link Clustering}\label{CLC}
Also known as ``farthest neighbor clustering'', Complete-Linkage Clustering ``[t]ends to find compact clusters with equal diameters'' (\cite{Everitt2011}). It does so by defining the distance between two clusters as the maximum distance between their members, see equation \ref{eq:CLC}, from \cite{Shalizi2009}. 

\begin{equation}\label{eq:CLC}
d(A,B) = \max_{\vec{x} \in A,\,\vec{y} \in B} ||\vec{x}  - \vec{y}||
\end{equation}


Instead of using euclidean distance, as is the norm, we instead define the distance between two points as the SNR between them. Note that this ``reverses'' the algorithm's logic, meaning that instead of finding the minimum distance among all maximum distances in a cluster for a merge, we find the maximum SNR among all minimum SNRs inside a cluster. The algorithm then takes two clusters with the smallest such SNR ``distance'' and merges them.  Normally, it would continue to do so until there are no more clusters to merge, i.e. there only remains one cluster containing all the points in the set. In order to avoid this, with every potential merge of two clusters, we check if the potential D2D link is over a certain threshold. For this threshold we chose the same threshold introduced in section \ref{RAP}, $10 \text{dB}$. When no further links under that level are possible, the algorithms stops. The fact that we are using only single-hop aggregation constrains our options quite starkly; a viable link must be possible to all members of the cluster.

In this type of scheme, the election of the cluster head seems almost arbitrary. In order to maintain verisimilitude of the simulation, we designate the UE with the smallest average distance to all other UEs as the cluster head.

\subsection{Single-Link Clustering}\label{SLC}
The ``nearest neighbor technique'', second of the best-known hierarchichal algorithms and ``one of the simplest hierarchical clustering methods'' (\cite{Everitt2011}) defines the distance between two clusters as ``the minimum distance between their members'', see equation \ref{eq:SLC}. This means that only one link will define the proximity between two entities, regardless of the density of the points inside them.

\begin{equation}\label{eq:SLC}
d(A,B) = \min_{\vec{x} \in A,\,\vec{y} \in B} ||\vec{x}  - \vec{y}||
\end{equation}

Here, too, we redefine the distance between to points as the SNR between the two. Despite its similarity to Complete-Link (see above, section \ref{CLC}), the nature of the algorithm makes it ``[not] care about compactness or balance'' \cite{Shalizi2009}. Preliminary tests showed that setting the same criteria for stopping as in Complete-Link would result most often in a gigantic, all-encompassing cluster containing all UEs, completely negating the effect of data aggregation. 

Consequently, we defined a stopping criteria not based on a threshold $SNR$, but rather on a threshold percentage of UEs serving as clusters $P_{SINGLE}$, analogous to the $P_{LEACH}$ of LEACH. The resulting number of clusters is then defined as 
\begin{equation}
\text{Desired number of clusters} = P_{SINGLE}\,\cdot\,\lambda\,.
\end{equation}
The values chosen for $P_{SINGLE}$ cover the same range as those of $P_{LEACH}$. This adjustment makes comparison with the other clustering algorithms significantly easier and allows us to still use Single-Link as an algorithm. Here, just as in Complete-Link, we define the cluster head as the UE with the lowest average distance to all other UEs.

\subsection{Ward's Method}\label{WM}
Originally formulated as an approach in 1963, in \cite{Ward1963}, Ward's method provides an interesting cost metric for the merging of two clusters. As stated more succinctly in \cite{Shalizi2009}, the method ``says that the distance between two clusters, A and B, is how much the sum of squares will increase when we merge them''. Ward formulates a merging cost $\Delta(A,B)$ based on the the distance between the geographical center of each cluster and utilizes this information to merge the two clusters with the lowest cost:

\begin{equation}\label{eq:wards_cost}
\Delta(A,B) = \frac {n_A\,n_B}{n_A + n_B}\,||\vec{m_A} - \vec{m_B}||^2\,,
\end{equation}
with $n_A$ and $n_B$ the number of points in the cluster and $\vec{m_A}$ and $\vec{m_B}$ the center of clusters A and B. The ``center'' of the cluster in our own implementation remains the geographical center.

Here again, a limit must be provided for the algorithm not to form a single gigantic cluster; we continue using the D2D communication threshold $10 \text{dB}$. When the algorithm detects that there are no further connections possible over the given limit, it stops. A simple implementation of the algorithm can be observed in figure \ref{fig:ward_math}.

\begin{figure}
\centering
\includegraphics[width=.4\linewidth]{figures/ward_math}
\caption{Sample clustering as a result of Ward's Method \cite{Shalizi2009}}
\label{fig:ward_math}
\end{figure}

The assignment of the cluster head occurs as in both of the other hierarchical algorithms.